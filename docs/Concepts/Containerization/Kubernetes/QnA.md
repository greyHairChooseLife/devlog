---
hide:
title: "스스로 질문하기"
date: 2024-04-04
update: 2024-04-05
---

## QnA

### 1. 하지만 서로 다른 독립된 서버(시스템)인데 어떻게 자기들이 하나의 클러스터에 속해있다는 것을 알 수 있어?

쿠버네티스 클러스터에서 서로 다른 독립된 서버(노드)들이 하나의 클러스터로 함께 작동할 수 있는 이유는 클러스터의 구성 정보와 네트워킹 설정에 의해서입니다. 클러스터를 구성할 때 각 노드는 쿠버네티스 클러스터의 컨트롤 플레인(주로 API 서버)에 등록되며, 이 과정에서 서로를 인식하고 클러스터의 일부로서 작동하게 됩니다. 이 과정을 좀 더 자세히 설명하겠습니다.

#### 클러스터 구성 및 노드 등록

1. **쿠버네티스 설치 및 초기화**: 클러스터를 생성할 때, 먼저 컨트롤 플레인을 호스트하는 하나 이상의 서버(마스터 노드)에 쿠버네티스 소프트웨어를 설치하고 초기화합니다. 이 과정에서 클러스터의 구성 정보와 통신할 수 있는 API 서버의 주소가 설정됩니다.

2. **노드 등록**: 워커 노드를 클러스터에 추가하려면, 각 워커 노드에 쿠버네티스 소프트웨어(주로 kubelet)를 설치한 다음, 이들을 컨트롤 플레인에 등록해야 합니다. 이 때 `kubeadm join`과 같은 명령어를 사용하여 API 서버의 주소와 클러스터에 조인하기 위한 토큰 또는 인증 정보를 제공합니다.

#### 클러스터 네트워킹

- **네트워킹 설정**: 클러스터 내부 통신을 가능하게 하기 위해, 쿠버네티스는 각 노드에 포드 네트워크를 구성합니다. 이를 위해 CNI(Container Network Interface) 플러그인을 사용하여 모든 노드가 공통의 네트워킹 네임스페이스를 공유하고, 각 포드가 클러스터 내에서 유니크한 IP 주소를 가질 수 있도록 합니다.

- **서비스 디스커버리**: 클러스터 내의 서비스는 DNS를 통해 서비스 디스커버리를 제공합니다. 쿠버네티스는 내부 DNS 서비스(CoreDNS)를 통해 이름을 IP 주소로 매핑하며, 이를 통해 포드나 서비스가 서로를 찾고 통신할 수 있습니다.

#### 쿠버네티스 구성 요소의 통신

- **API 서버와의 통신**: 모든 노드에 설치된 `kubelet`은 주기적으로 API 서버와 통신하여 노드의 상태를 보고하고, 컨트롤 플레인으로부터 새로운 작업(포드 배포 명령 등)을 받습니다. 이렇게 하여 클러스터의 상태가 중앙에서 관리되며, 클러스터 내 모든 구성 요소가 일관된 상태를 유지할 수 있습니다.

이러한 방식으로, 서로 다른 서버들은 쿠버네티스 클러스터의 일부로서 구성 정보를 공유하고, 공통된 네트워킹 규칙을 따르며, 중앙의 컨트롤 플레인을 통해 조정됩니다. 따라서 모든 노드는 하나의 클러스터에 속해 있다는 것을 알고, 클러스터의 다른 부분과 협력하여 작동할 수 있습니다.

### 2. 반드시 단일 워커노드여야해? 워커노드를 추가로 생성할수는 없어?

> 그리고 좀 의문인게 단일 컨테이너 내에서 클러스터를 구성하지 말고 마스터노드 하나, 워커노드 하나, 다른 워커노드 하나, 필수 컴포넌트(오브젝트)들을 모아서 하나 이런식으로 다만 몇개의 컨테이너로 나누기만 해도 컨트롤 플레인에 kubelet을 등록하는 실전적 연습도 해볼 수 있을텐데말이야.  
> 이런 연습도 해볼 수 있게 자유도를 제공하는 minikube의 대체제가 있을까?

`minikube`는 기본적으로 로컬 환경에서 쿠버네티스 클러스터를 쉽게 시작하고 테스트하기 위한 도구로, 주로 단일 노드 클러스터를 생성합니다. 이는 개발, 학습, 그리고 테스트 목적에 적합하도록 설계되었기 때문입니다. `minikube`로 여러 워커 노드를 추가하는 것은 직접적으로 지원되지 않습니다.

그러나 쿠버네티스를 좀 더 실제와 가까운 환경에서 실험하고 싶다면, 여러 워커 노드를 포함하는 클러스터를 구성할 수 있는 다른 도구들을 고려할 수 있습니다. 이러한 도구들은 보다 복잡한 쿠버네티스 클러스터 구성을 실험하고자 할 때 유용합니다. 여기에는 다음과 같은 대체 도구들이 있습니다:

#### kubeadm

- `kubeadm`은 쿠버네티스 클러스터를 부트스트랩하는 도구로, 컨트롤 플레인과 여러 워커 노드를 포함하는 클러스터를 수동으로 구성할 수 있습니다. `kubeadm`을 사용하면, 실제 클러스터 환경에서 쿠버네티스를 실행하고 관리하는 데 필요한 경험을 쌓을 수 있습니다.

#### kind (Kubernetes IN Docker)

- `kind`는 Docker 컨테이너 내에서 쿠버네티스 클러스터를 실행하기 위해 설계된 도구입니다. `kind`는 테스트 및 CI 환경에 적합하며, 여러 노드를 포함하는 클러스터 구성을 지원합니다. 각 노드는 별도의 Docker 컨테이너로 실행되기 때문에, `kind`를 사용하면 여러 노드를 가진 클러스터를 로컬에서 손쉽게 시뮬레이션할 수 있습니다.

#### K3s 및 K3d

- **K3s**는 경량화된 쿠버네티스 배포판으로, 제한된 리소스를 가진 환경에서도 실행될 수 있도록 최적화되어 있습니다. IoT 디바이스, 개발 환경, CI 파이프라인 등 다양한 용도로 사용될 수 있습니다.
- **K3d**는 K3s 클러스터를 Docker 컨테이너 내에서 실행하는 도구입니다. 이를 통해 로컬 환경에서 간편하게 여러 노드를 포함하는 K3s 클러스터를 생성하고 관리할 수 있습니다.

각 도구는 특정 사용 사례와 요구 사항에 따라 장단점이 있으며, 여러 워커 노드를 포함하는 클러스터를 구성하거나 보다 복잡한 쿠버네티스 클러스터 구성을 실험하고 싶을 때 유용합니다. `kubeadm`, `kind`, 그리고 `K3d`는 모두 쿠버네티스 클러스터를 로컬 환경에서 실행하면서 컨트롤 플레인과 워커 노드 간의 통신, 클러스터 관리, 애플리케이션 배포 등에 대해 학습하고 실습할 수 있는 기회를 제공합니다.

> 보여준 4개의 도구 중에서 간단한 서비스를 위한 실제 프로덕션 레벨로 사용되는 도구는 무엇이야?

실제 프로덕션 레벨의 클러스터를 구성하고 운영하기 위해서는 `kubeadm`이 가장 적합한 도구 중 하나입니다. `kubeadm`은 쿠버네티스 공식 문서에서도 프로덕션 환경을 위한 클러스터 구성 도구로 권장되며, 커뮤니티의 광범위한 지원을 받고 있습니다.

#### kubeadm

- **프로덕션 환경**: `kubeadm`은 다중 노드 클러스터를 구성하는 과정을 단순화하고, 고가용성, 보안 설정, 네트워킹 구성 등 프로덕션 환경에서 요구되는 다양한 기능을 제공합니다.
- **유연성과 확장성**: 사용자는 `kubeadm`을 사용하여 커스텀 클러스터 구성, 노드 추가 및 제거, 클러스터 업그레이드, 보안 설정 조정 등 다양한 작업을 수행할 수 있습니다.
- **커뮤니티 및 공식 지원**: `kubeadm`은 쿠버네티스 프로젝트의 일부로 개발되고 유지 관리되며, 쿠버네티스 공식 문서와 커뮤니티 포럼에서 광범위한 지원을 받습니다.

#### kind, K3s, K3d

- **kind**와 **K3d**는 주로 개발 및 테스트 환경, CI/CD 파이프라인 구성을 위해 설계되었습니다. 이 도구들은 로컬 환경에서 간편하게 쿠버네티스 클러스터를 구성하고 실험할 수 있게 해주지만, 제한된 리소스와 단순화된 네트워킹 옵션으로 인해 대규모 프로덕션 환경에는 적합하지 않을 수 있습니다.
- **K3s**는 경량화된 쿠버네티스 배포판으로, IoT, Edge Computing, 소규모 클라우드 환경에서의 사용이나, 리소스가 제한된 환경에서의 프로덕션 사용에 적합합니다. 그러나 대규모 데이터 센터 또는 복잡한 멀티 클러스터 환경에서는 `kubeadm`을 통해 구성된 표준 쿠버네티스 클러스터가 더 나은 선택일 수 있습니다.

따라서, 간단한 서비스를 위한 실제 프로덕션 레벨의 클러스터를 구성하고자 한다면, `kubeadm`을 사용하는 것이 가장 좋은 선택입니다. `kubeadm`을 통해 확장성이 높고 관리가 용이한 클러스터를 구성할 수 있으며, 쿠버네티스 클러스터의 전체 라이프사이클 관리에 필요한 기능을 제공받을 수 있습니다.

### 3. STATE:running인 pod가 있는데 master node만 조회 된다. 이럴수가 있나?

내가 minikube를 사용하고 있어서 그렇다. minikube는 단일 노드 클러스터를 제공하는데, 이 마스터노드 혼자서 control-plane역할과 worker-node 역할을 모두 할 수 있다.

### 3. (master node 내에) 동일한 resource의 controller들은 서로 같은 selector를 가질 수 있을까?

그렇다. 그러나 꼭 필요한 경우가 아니라면 label은 고유하게 관리하는 것이 좋다.

상용 자동차 대부분이 오토미션을 쓰지만 고급 운전자에겐 수동 미션이 필요한 것처럼, 고급 사용자에겐 이유가 있나보다.

### 4. 동일한 리소스 타입(kind)의 yml 파일을 여러개 만들면 컨트롤러도 그만큼 다수 생길까?

아니다. 리소스가 많아지면 컨트롤러가 많아지는 것이 아니라, 컨트롤러가 리소스를 관리하는 대상이 많아지는 것이다.

**API그룹**이 다르다거나, 라벨을 통해 dev/prod 따위로 구분된다 하여도 컨트롤러는 하나다.

<details>
<summary>API 그룹이란?</summary>

`kubectl get <resource>` 명령을 통해 쿠버네티스 클러스터 내의 리소스를 조회할 때, 리소스의 `NAME`은 `<리소스 유형>/<리소스 이름>` 의 형태로 표시된다.

```sh
NAME                           READY   STATUS    RESTARTS   AGE
pod/echo-dp-7f45545895-5rmtm   1/1     Running   0          16m
pod/echo-dp-7f45545895-86hs9   1/1     Running   0          16m
pod/echo-dp-7f45545895-g9766   1/1     Running   0          16m
pod/echo-dp-7f45545895-w9fpn   1/1     Running   0          16m

NAME                                 DESIRED   CURRENT   READY   AGE
replicaset.apps/echo-dp-68fd75c85b   0         0         0       36m
replicaset.apps/echo-dp-7f45545895   4         4         4       16m

NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/echo-dp   4/4     4            4           36m
```

이때, `<리소스 유형>`에 `.<API group>`이 함께 표시된다. 각각은 쿠버네티스 API 내에서 리소스를 그룹화하고 관리하는 방식을 나타낸다. 예를 들어, `Deployment` 리소스는 `apps` API 그룹에 속해 있으므로, `kubectl get` 명령을 통해 조회할 때 `deployment.apps`와 같이 표시된다.

이는 쿠버네티스에서 직접 제공한다. 아래는 API 그룹의 일부 예시이다.

#### `Core` (핵심 그룹)

- **경로**: `/api/v1`
- **리소스**: `Pods`, `Services`, `Namespaces`, `ConfigMaps`, `Events`, `Endpoints`, `PersistentVolumes`, `PersistentVolumeClaims` 등
- **설명**: 쿠버네티스의 가장 기본적인 리소스를 제공합니다. 핵심 그룹은 특별한 그룹 이름 없이 사용됩니다.

#### `batch`

- **경로**: `/apis/batch/v1`
- **리소스**: `Jobs`, `CronJobs`
- **설명**: 일회성 작업 또는 예약된 작업을 실행하기 위한 리소스를 포함합니다.

#### `autoscaling`

- **경로**: `/apis/autoscaling/v1`
- **리소스**: `HorizontalPodAutoscalers`
- **설명**: 애플리케이션의 스케일을 자동으로 조절하기 위한 리소스를 포함합니다.

#### `networking.k8s.io`

- **경로**: `/apis/networking.k8s.io/v1`
- **리소스**: `Ingress`, `NetworkPolicies`
- **설명**: 클러스터 내 네트워크 통신 규칙 및 외부로의 접근을 관리하는 데 사용되는 리소스를 포함합니다.

#### `rbac.authorization.k8s.io`

- **경로**: `/apis/rbac.authorization.k8s.io/v1`
- **리소스**: `Roles`, `RoleBindings`, `ClusterRoles`, `ClusterRoleBindings`
- **설명**: 리소스 접근 권한을 제어하는데 사용되는 Role-Based Access Control(RBAC) 관련 리소스를 포함합니다.

#### `storage.k8s.io`

- **경로**: `/apis/storage.k8s.io/v1`
- **리소스**: `StorageClasses`, `VolumeAttachments`
- **설명**: 스토리지 클래스 및 볼륨 첨부 정보와 같은, 스토리지 관련 리소스를 제공합니다.

#### `apiextensions.k8s.io`

- **경로**: `/apis/apiextensions.k8s.io/v1`
- **리소스**: `CustomResourceDefinitions` (CRDs)
- **설명**: 사용자가 정의한 리소스를 쿠버네티스 API에 추가할 수 있게 해주는 리소스를 포함합니다.

이외에도 쿠버네티스는 `admissionregistration.k8s.io`, `scheduling.k8s.io`, `coordination.k8s.io`와 같은 다양한 API 그룹을 제공하며, 쿠버네티스의 기능과 확장성을 증대시킵니다. 각 API 그룹은 쿠버네티스 클러스터를 효율적으로 운영하고 관리하기 위한 특정 범주의 리소스와 기능을 제공합니다.

</details>
